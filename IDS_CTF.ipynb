{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parmigggiana/ml-ids/blob/main/IDS_CTF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGLYJuXmFBZI"
      },
      "source": [
        "# Attack detection using CTF dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEXk3Cipho3k"
      },
      "source": [
        "You shouldn't use 'Run All' on this notebook: in the sections 'Dimensionality Reduction' and 'Training' only run one of the subsections for each.\n",
        "If you run all the cells it won't cause any error, just waste time on operations that will then be overwritten."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJVAToeYFV2Q"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import HalvingGridSearchCV\n",
        "from sklearn.cluster import KMeans, MeanShift, FeatureAgglomeration\n",
        "from pandas.plotting import scatter_matrix\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqkUwYVfho3o"
      },
      "source": [
        "## Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SC_AoGB5ho3p"
      },
      "outputs": [],
      "source": [
        "def print_scores(y_test, y_pred):\n",
        "    auroc = metrics.roc_auc_score(y_test, y_pred)\n",
        "    if auroc < 0.5:\n",
        "        y_pred = [0 if x == 1 else 1 for x in y_pred] # If it's worse than random guessing we flip it - we're not cheating here, the prediction just doesn't have a concept of benign or attack, it just identifies two clusters. if auroc was less than 0.5 it means we labelled them wrong\n",
        "        auroc = metrics.roc_auc_score(y_test, y_pred)\n",
        "    Accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "    Precision = metrics.precision_score(y_test, y_pred)\n",
        "    Recall = metrics.recall_score(y_test, y_pred)\n",
        "    F1 = metrics.f1_score(y_test, y_pred)\n",
        "    fpr, tpr, threasholds = metrics.roc_curve(y_test, y_pred)\n",
        "    \"\"\"\n",
        "    Confusion matrix:\n",
        "\n",
        "        0  1 - predicted value (Wikipedia uses different convention for axes)\n",
        "        0 TN FP\n",
        "        1 FN TP\n",
        "    \"\"\"\n",
        "    cf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
        "    group_names = ['TN','FP','FN', 'TP']\n",
        "    group_counts = [f\"{value}\" for value in\n",
        "                cf_matrix.flatten()]\n",
        "    group_percentages = [f\"{value:.2f}%\" for value in\n",
        "                     cf_matrix.flatten()/np.sum(cf_matrix)]\n",
        "    labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
        "          zip(group_names, group_counts, group_percentages)]\n",
        "    labels = np.asarray(labels).reshape(2,2)\n",
        "    sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=labels, fmt='', cmap='mako') # thx https://medium.com/@dtuk81/confusion-matrix-visualization-fc31e3f30fea\n",
        "\n",
        "    print(f\"{Accuracy = }\")\n",
        "    print(f\"{Precision = }\")\n",
        "    print(f\"{Recall = }\")\n",
        "    print(f\"Area Under ROC Curve = {auroc}\")\n",
        "    print(f\"{F1 = }\")\n",
        "    plt.figure(figsize=(5, 4))\n",
        "    plt.plot(fpr, tpr)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Sz9zzUjho3q"
      },
      "outputs": [],
      "source": [
        "def load_test(scaler, dimred):\n",
        "    if 'test_df' not in globals():\n",
        "        test_df = pd.read_csv(filepath_or_buffer=\"definitive_dataset.csv\")\n",
        "\n",
        "    y_test = test_df[\"Label\"]\n",
        "    X_test = test_df.drop(columns=\"Label\")\n",
        "    X_test = scaler.transform(X_test)\n",
        "    X_test = dimred.transform(X_test)\n",
        "\n",
        "    return X_test, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hA8QpGEwho3r"
      },
      "outputs": [],
      "source": [
        "def visualize_features(X):\n",
        "    corr_matrix = pd.DataFrame(X).corr()\n",
        "    plt.rcParams['figure.figsize'] = (18, 8)\n",
        "    g = sns.heatmap(corr_matrix, annot=True, fmt=\".1g\", cmap=\"Greys\")\n",
        "    g.set_xticklabels(\n",
        "        g.get_xticklabels(),\n",
        "        verticalalignment=\"top\",\n",
        "        horizontalalignment=\"right\",\n",
        "        rotation=30,\n",
        "    )\n",
        "    plt.show()\n",
        "    scatter_matrix(pd.DataFrame(X), alpha=0.2, figsize=(20, 20), diagonal=\"kde\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-9PXXNaho3r"
      },
      "source": [
        "## Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9A526YEoqe1K"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/parmigggiana/ml-ids/raw/main/CTF%20Data/Thu15.csv -O dataset_ctf.csv\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIqeKHKYGCoz"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"CTF Data/Thu15.csv\")\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLMdekcqho3u"
      },
      "source": [
        "Make sure that there's no null rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ltfHW8dh7Tw"
      },
      "outputs": [],
      "source": [
        "df = df.drop(df[pd.isnull(df[\"Flow ID\"])].index)\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFPHGpA8ho3v"
      },
      "source": [
        "Drop Label column since it's useless"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEqbD5w1ho3v"
      },
      "outputs": [],
      "source": [
        "df.drop(columns=\"Label\", inplace=True)\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fLhU16gho3w"
      },
      "source": [
        "Drop all flows pertaining ssh and caronte"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJVBxG8xho3w"
      },
      "outputs": [],
      "source": [
        "df.drop(df[df[\"Src Port\"] == 22].index, inplace=True)\n",
        "df.drop(df[df[\"Dst Port\"] == 22].index, inplace=True)\n",
        "df.drop(df[df[\"Src Port\"] == 3333].index, inplace=True)\n",
        "df.drop(df[df[\"Dst Port\"] == 3333].index, inplace=True)\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByM4xWKZho3x"
      },
      "source": [
        "Drop all flows made by our team"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJuQbwkAho3x"
      },
      "outputs": [],
      "source": [
        "df.drop(df[df[\"Src IP\"].str.fullmatch(r\"10\\.80\\.39\\.\\d{1,3}\")].index, inplace=True)\n",
        "df.drop(df[df[\"Dst IP\"].str.fullmatch(r\"10\\.80\\.39\\.\\d{1,3}\")].index, inplace=True)\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pp3zFw35ho3y"
      },
      "outputs": [],
      "source": [
        "df[\"Src IP\"].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpoXgIJRho3y"
      },
      "source": [
        "I noticed there's 1784 flows belonging to other addresses. This probably means there's an error in the gameserver, leaking some packets. Upon manual inspection of the pcap, I noticed they are mostly FIN/ACK and RST.\n",
        "I chose to keep these flows as it's still actual traffic and we will be removing the IP features anyway"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z962m9WCho3y"
      },
      "outputs": [],
      "source": [
        "df[\n",
        "    ((df[\"Src IP\"] != \"10.254.0.1\") & (df[\"Src IP\"] != \"10.60.39.1\"))\n",
        "    | ((df[\"Dst IP\"] != \"10.254.0.1\") & (df[\"Dst IP\"] != \"10.60.39.1\"))\n",
        "].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZN6DKttXiH7J"
      },
      "source": [
        "The \"Flow Bytes/s\" and \"Flow Packets/s\" columns have non-numerical values, replace them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZ2ffToLi02x"
      },
      "outputs": [],
      "source": [
        "df.replace(\"Infinity\", -1, inplace=True)\n",
        "df[[\"Flow Bytes/s\", \"Flow Packets/s\"]] = df[[\"Flow Bytes/s\", \"Flow Packets/s\"]].apply(\n",
        "    pd.to_numeric\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAVqCLK8qe1P"
      },
      "source": [
        "Replace the NaN values and infinity values with -1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgZGWpa0qe1P"
      },
      "outputs": [],
      "source": [
        "df.replace([np.inf, -np.inf, np.nan], -1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1k2G5UAEt9cw"
      },
      "source": [
        "7 features (Flow ID, Source IP, Source Port, Destination IP, Destination Port, Protocol, Timestamp) are excluded from the dataset. The hypothesis is that the \"shape\" of the data being transmitted is more important than these attributes. In addition, ports and addresses can be substituted by an attacker, so it is better that the ML algorithm does not take these features into account in training [Kostas2018]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yza95R2t_1N"
      },
      "outputs": [],
      "source": [
        "excluded = [\n",
        "    \"Flow ID\",\n",
        "    \"Src IP\",\n",
        "    \"Src Port\",\n",
        "    \"Dst IP\",\n",
        "    \"Dst Port\",\n",
        "    \"Protocol\",\n",
        "    \"Timestamp\",\n",
        "]\n",
        "df.drop(columns=excluded, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZrJzhlRho30"
      },
      "source": [
        "## Dimensionality Reduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqptBL9sho30"
      },
      "source": [
        "We don't have labels to select features based on importance. A simple approach would be using the same features selected on the CIC-IDS-2017 Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6XpSbvxho30"
      },
      "source": [
        "### Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CeuNJ5Bhho30"
      },
      "outputs": [],
      "source": [
        "features = [\n",
        "    \"RST Flag Count\",\n",
        "    \"Total Length of Fwd Packet\",\n",
        "    \"Fwd Packet Length Max\",\n",
        "    \"Packet Length Variance\",\n",
        "    \"Fwd Packets/s\",\n",
        "    \"Fwd Packet Length Mean\",\n",
        "    \"Flow IAT Max\",\n",
        "    \"Flow Duration\",\n",
        "    \"Flow Packets/s\",\n",
        "    \"Total TCP Flow Time\",\n",
        "    \"PSH Flag Count\",\n",
        "    \"Packet Length Min\",\n",
        "    \"Bwd IAT Total\",\n",
        "    \"FWD Init Win Bytes\",\n",
        "    \"Flow Bytes/s\",\n",
        "    \"ACK Flag Count\",\n",
        "    \"Fwd Header Length\",\n",
        "    \"SYN Flag Count\",\n",
        "    \"Total Bwd packets\",\n",
        "]\n",
        "X = df[features]\n",
        "scaler = RobustScaler()\n",
        "scaler.fit(X)\n",
        "X = scaler.transform(X)\n",
        "\n",
        "visualize_features(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmAw1-Mkho30"
      },
      "source": [
        "We can see how many of the selected features are practically independent from the dataset. This means they don't bring much information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcXMwErlho31"
      },
      "source": [
        "### PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mpv49aDgho31"
      },
      "outputs": [],
      "source": [
        "scaler = RobustScaler()\n",
        "scaler.fit(df)\n",
        "X = scaler.transform(df)\n",
        "\n",
        "dimred = PCA(20, random_state=42)\n",
        "dimred.fit(X)\n",
        "X = dimred.transform(X)\n",
        "\n",
        "visualize_features(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JxJjNPPho31"
      },
      "source": [
        "### Feature Agglomeration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ybxw2xWho31"
      },
      "outputs": [],
      "source": [
        "scaler = RobustScaler()\n",
        "scaler.fit(df)\n",
        "X = scaler.transform(df)\n",
        "\n",
        "dimred = FeatureAgglomeration(n_clusters=20)\n",
        "dimred.fit(X)\n",
        "X = dimred.transform(X)\n",
        "\n",
        "visualize_features(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucW7bmaPho31"
      },
      "source": [
        "## Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIuCansnho31"
      },
      "outputs": [],
      "source": [
        "clf: KMeans = KMeans(2, random_state=42, verbose=10)\n",
        "\n",
        "param_grid = {\n",
        "    \"algorithm\": [\"lloyd\", \"elkan\"],\n",
        "    \"max_iter\": [100, 300, 650, 1000, 2000],\n",
        "    \"n_init\": [1, 2, 5, 10, 20],\n",
        "}\n",
        "search = HalvingGridSearchCV(clf, param_grid=param_grid, n_jobs=-1, verbose=10).fit(X)\n",
        "clf: KMeans = search.best_estimator_\n",
        "\n",
        "X_test, y_test = load_test(scaler, dimred)\n",
        "y_pred = clf.predict(X_test)\n",
        "print(search.best_estimator_)\n",
        "print(search.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNe2OVR0ho31"
      },
      "source": [
        "### MeanShift"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iaEh2I5lho36"
      },
      "outputs": [],
      "source": [
        "clf = MeanShift(max_iter=300, n_jobs=-1)\n",
        "clf.fit(X)\n",
        "\n",
        "\"\"\"\n",
        "MeanShift outputs 107 classes. To project them into binary I iteratively tried considering every class a benign or not, maximizing the F1 score on the test dataset (Corrected CIC-IDS-2017).\n",
        "\"\"\"\n",
        "X_test, y_test = load_test(scaler, dimred)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "benign_classes = []\n",
        "y_pred_tmp = y_pred.tolist()\n",
        "classes = np.unique(y_pred)\n",
        "for c in classes:\n",
        "    y_pred_ben = [0 if x == c else x for x in y_pred_tmp]\n",
        "    y_pred_att = [1 if x == c else x for x in y_pred_tmp]\n",
        "\n",
        "    y_pred_ben = [1 if x != 0 else x for x in y_pred_ben]\n",
        "    y_pred_att = [1 if x != 0 else x for x in y_pred_att]\n",
        "\n",
        "    F1_B = metrics.f1_score(y_test, y_pred_ben)\n",
        "    F1_A = metrics.f1_score(y_test, y_pred_att)\n",
        "\n",
        "    print(f\"F1 with class {c} as BENIGN: {F1_B}\")\n",
        "    print(f\"F1 with class {c} as ATTACK: {F1_A}\")\n",
        "    print(\"\\n\")\n",
        "    if F1_B > F1_A:\n",
        "        benign_classes.append(c)\n",
        "    y_pred_tmp = [0 if x in benign_classes else x for x in y_pred]\n",
        "\n",
        "# print(f\"{benign_classes = }\")\n",
        "y_pred = [1 if x != 0 else x for x in y_pred_tmp]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sr3Z24hcho36"
      },
      "source": [
        "### Isolation Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzhJqKfeho36"
      },
      "outputs": [],
      "source": [
        "clf: IsolationForest = IsolationForest(\n",
        "    n_estimators=200, max_features=10, bootstrap=True, random_state=42, verbose=1\n",
        ")\n",
        "\n",
        "clf.fit(X)\n",
        "\n",
        "X_test, y_test = load_test(scaler, dimred)\n",
        "y_pred = clf.predict(X_test)  # output is -1 | 1\n",
        "y_pred = [0 if x == -1 else 1 for x in y_pred]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PjbLgCgho36"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Tc40M3Sho37"
      },
      "outputs": [],
      "source": [
        "print_scores(y_test, y_pred)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "SCEkDfpOFPQX",
        "-IEyQxBDt5sG",
        "wE4AwrX1u6Hj",
        "suPDWnoYaEPD",
        "duGKUsAzal52",
        "eLikdx9Legm0"
      ],
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}