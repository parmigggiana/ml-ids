{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parmigggiana/ml-ids/blob/main/IDS_CTF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tGLYJuXmFBZI"
      },
      "source": [
        "# Attack detection using CTF dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJVAToeYFV2Q"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.model_selection import HalvingGridSearchCV\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.cluster import KMeans, MeanShift, FeatureAgglomeration\n",
        "from pandas.plotting import scatter_matrix\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def print_scores(y_test, y_pred):\n",
        "    Accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "    Precision = metrics.precision_score(y_test, y_pred)\n",
        "    Recall = metrics.recall_score(y_test, y_pred)\n",
        "    F1 = metrics.f1_score(y_test, y_pred)\n",
        "    fpr, tpr, threasholds = metrics.roc_curve(y_test, y_pred)\n",
        "    auroc = metrics.roc_auc_score(y_test, y_pred)\n",
        "    \"\"\" \n",
        "    Confusion matrix:\n",
        "\n",
        "        0  1 - predicted value (Wikipedia uses different convention for axes)\n",
        "        0 TN FP\n",
        "        1 FN TP \n",
        "    \"\"\"\n",
        "    print(metrics.confusion_matrix(y_test, y_pred))\n",
        "    print(f'{Accuracy = }')\n",
        "    print(f'{Precision = }')\n",
        "    print(f'{Recall = }')\n",
        "    print(f\"Area Under ROC Curve = {auroc}\")\n",
        "    print(f'{F1 = }')\n",
        "    plt.figure(figsize=(5,4))\n",
        "    plt.plot(fpr, tpr)\n",
        "    plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9A526YEoqe1K",
        "outputId": "7aa88604-3f05-4fea-be89-3c1f57b8d5ac"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/parmigggiana/ml-ids/raw/main/CTF%20Data/ctf_flows_1.csv -O dataset_ctf.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIqeKHKYGCoz"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('CTF Data/Thu15.csv')\n",
        "df.shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Make sure that there's no null rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ltfHW8dh7Tw",
        "outputId": "2653ed15-a87d-4d89-943c-329ca4fbdf3b"
      },
      "outputs": [],
      "source": [
        "df = df.drop(df[pd.isnull(df['Flow ID'])].index)\n",
        "df.shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Drop Label column since it's useless"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.drop(columns='Label', inplace=True)\n",
        "df.shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Drop all flows pertaining ssh and caronte"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.drop(df[df['Src Port'] == 22].index, inplace=True)\n",
        "df.drop(df[df['Dst Port'] == 22].index, inplace=True)\n",
        "df.drop(df[df['Src Port'] == 3333].index, inplace=True)\n",
        "df.drop(df[df['Dst Port'] == 3333].index, inplace=True)\n",
        "df.shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Drop all flows made by our team"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.drop(df[df['Src IP'].str.fullmatch(r\"10\\.80\\.39\\.\\d{1,3}\")].index, inplace=True)\n",
        "df.drop(df[df['Dst IP'].str.fullmatch(r\"10\\.80\\.39\\.\\d{1,3}\")].index, inplace=True)\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['Src IP'].unique()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I noticed there's 1784 flows belonging to other addresses. This probably means there's an error in the gameserver, leaking some packets. Upon manual inspection of the pcap, I noticed they are mostly FIN/ACK and RST. \n",
        "I chose to keep these flows as it's still actual traffic and we will be removing the IP features anyway"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[\n",
        "    ((df[\"Src IP\"] != \"10.254.0.1\") & (df[\"Src IP\"] != \"10.60.39.1\"))\n",
        "    | ((df[\"Dst IP\"] != \"10.254.0.1\") & (df[\"Dst IP\"] != \"10.60.39.1\"))\n",
        "].shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZN6DKttXiH7J"
      },
      "source": [
        "The \"Flow Bytes/s\" and \"Flow Packets/s\" columns have non-numerical values, replace them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZ2ffToLi02x"
      },
      "outputs": [],
      "source": [
        "df.replace('Infinity', -1, inplace=True)\n",
        "df[[\"Flow Bytes/s\", \"Flow Packets/s\"]] = df[[\"Flow Bytes/s\", \"Flow Packets/s\"]].apply(pd.to_numeric)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OAVqCLK8qe1P"
      },
      "source": [
        "Replace the NaN values and infinity values with -1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgZGWpa0qe1P"
      },
      "outputs": [],
      "source": [
        "df.replace([np.inf, -np.inf, np.nan], -1, inplace=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1k2G5UAEt9cw"
      },
      "source": [
        "7 features (Flow ID, Source IP, Source Port, Destination IP, Destination Port, Protocol, Timestamp) are excluded from the dataset. The hypothesis is that the \"shape\" of the data being transmitted is more important than these attributes. In addition, ports and addresses can be substituted by an attacker, so it is better that the ML algorithm does not take these features into account in training [Kostas2018]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yza95R2t_1N"
      },
      "outputs": [],
      "source": [
        "excluded = ['Flow ID', 'Src IP', 'Src Port', 'Dst IP', 'Dst Port', 'Protocol', 'Timestamp']\n",
        "df.drop(columns=excluded, inplace=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dimensionality Reduction"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We don't have labels to select features based on importance. A simple approach would be using the same features selected on the CIC-IDS-2017 Dataset "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = ['RST Flag Count', 'Total Length of Fwd Packet', 'Fwd Packet Length Max', 'Packet Length Variance', 'Fwd Packets/s', 'Fwd Packet Length Mean', 'Flow IAT Max', 'Flow Duration', 'Flow Packets/s', 'Total TCP Flow Time', 'PSH Flag Count', 'Packet Length Min', 'Bwd IAT Total', 'FWD Init Win Bytes', 'Flow Bytes/s', 'ACK Flag Count', 'Fwd Header Length', 'SYN Flag Count', 'Total Bwd packets']\n",
        "X = df[features]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "corr_matrix = df.corr()\n",
        "plt.rcParams['figure.figsize'] = (14, 6)\n",
        "g = sns.heatmap(corr_matrix, annot=True, fmt='.1g', cmap='Greys')\n",
        "g.set_xticklabels(g.get_xticklabels(), verticalalignment='top', horizontalalignment='right', rotation=30)\n",
        "plt.show()\n",
        "scatter_matrix(df, alpha=0.1, figsize=(20, 20), diagonal=\"kde\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "An alternative to selecting the features to use would be employing a dimensionality reduction algorithm.\n",
        "Before that, we need to normalize our dataset.\n",
        "I chose to use RobustScaler instead of StandardScaler because, by using the median, it is more resilient to inbalanced data."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler = RobustScaler()\n",
        "scaler.fit(df)\n",
        "X = scaler.transform(df)\n",
        "\n",
        "dimred = PCA(20, random_state=42)\n",
        "dimred.fit(X)\n",
        "X = dimred.transform(X)\n",
        "features = dimred.feature_names_in_\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_matrix = pd.DataFrame(X).corr()\n",
        "g = sns.heatmap(corr_matrix, annot=True, fmt='.1g', cmap='Greys')\n",
        "g.set_xticklabels(g.get_xticklabels(), verticalalignment='top', horizontalalignment='right', rotation=30)\n",
        "plt.show()\n",
        "scatter_matrix(pd.DataFrame(X), alpha=0.2, figsize=(20, 20), diagonal=\"kde\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Feature Agglomeration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler = RobustScaler()\n",
        "scaler.fit(df)\n",
        "X = scaler.transform(df)\n",
        "\n",
        "dimred = FeatureAgglomeration(n_clusters=15)\n",
        "dimred.fit(X)\n",
        "X = dimred.transform(X)\n",
        "features = dimred.feature_names_in_\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_matrix = pd.DataFrame(X).corr()\n",
        "g = sns.heatmap(corr_matrix, annot=True, fmt='.1g', cmap='Greys')\n",
        "g.set_xticklabels(g.get_xticklabels(), verticalalignment='top', horizontalalignment='right', rotation=30)\n",
        "plt.show()\n",
        "scatter_matrix(pd.DataFrame(X), alpha=0.2, figsize=(20, 20), diagonal=\"kde\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clf: KMeans = KMeans(2, random_state=42, verbose=10)\n",
        "\n",
        "param_grid = {\n",
        "    'algorithm': ['lloyd', 'elkan'], \n",
        "    'max_iter': [100, 300, 650, 1000, 2000], \n",
        "    'n_init': [1, 2, 5, 10, 20], \n",
        "}\n",
        "search = HalvingGridSearchCV(clf, param_grid=param_grid, n_jobs=-1, verbose=10).fit(X)\n",
        "clf: KMeans = search.best_estimator_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(search.best_estimator_)\n",
        "print(search.best_params_)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MeanShift"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clf = MeanShift(max_iter=300, n_jobs=-1)\n",
        "clf.fit(X)\n",
        "\n",
        "\"\"\"\n",
        "MeanShift outputs 107 classes. To project them into binary I iteratively tried considering every class a benign or not, maximizing the F1 score on the test dataset (Corrected CIC-IDS-2017). \n",
        "\"\"\"\n",
        "test_df = pd.read_csv(filepath_or_buffer='definitive_dataset.csv')\n",
        "y_test = test_df['Label']\n",
        "X_test = test_df.drop(columns='Label')\n",
        "X_test = scaler.transform(X_test)\n",
        "X_test = dimred.transform(X_test)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "benign_classes = []\n",
        "y_pred_tmp = y_pred.tolist()\n",
        "classes = np.unique(y_pred)\n",
        "for c in classes:    \n",
        "    y_pred_ben = [0 if x == c else x for x in y_pred_tmp]\n",
        "    y_pred_att = [1 if x == c else x for x in y_pred_tmp]\n",
        "\n",
        "    y_pred_ben = [1 if x != 0 else x for x in y_pred_ben]\n",
        "    y_pred_att = [1 if x != 0 else x for x in y_pred_att]\n",
        "\n",
        "    F1_B = metrics.f1_score(y_test, y_pred_ben)\n",
        "    F1_A = metrics.f1_score(y_test, y_pred_att)\n",
        "    \n",
        "    print(f\"F1 with class {c} as BENIGN: {F1_B}\")\n",
        "    print(f\"F1 with class {c} as ATTACK: {F1_A}\")\n",
        "    print('\\n')\n",
        "    if F1_B > F1_A:\n",
        "        benign_classes.append(c)\n",
        "    y_pred_tmp = [0 if x in benign_classes else x for x in y_pred]\n",
        "\n",
        "print(benign_classes)\n",
        "y_pred = [1 if x != 0 else x for x in y_pred_tmp]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Isolation Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clf: IsolationForest = IsolationForest(n_estimators=200, max_features=10, bootstrap=True, random_state=42, verbose=1)\n",
        "\n",
        "clf.fit(X)\n",
        "y_pred = clf.predict(X_test) # output is -1 | 1\n",
        "y_pred = [0 if x == -1 else 1 for x in y_pred]\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!wget https://intrusion-detection.distrinet-research.be/CNS2022/Datasets/CICIDS2017_improved.zip -O dataset.zip\n",
        "#!unzip -u -d Corrected_CICIDS2017/ dataset.zip \n",
        "test_df = pd.read_csv(filepath_or_buffer='definitive_dataset.csv')\n",
        "\n",
        "y_test = test_df['Label']\n",
        "X_test = test_df.drop(columns='Label')\n",
        "X_test = scaler.transform(X_test)\n",
        "X_test = dimred.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = clf.predict(X_test)\n",
        "print_scores(y_test, y_pred)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "SCEkDfpOFPQX",
        "-IEyQxBDt5sG",
        "wE4AwrX1u6Hj",
        "suPDWnoYaEPD",
        "duGKUsAzal52",
        "eLikdx9Legm0"
      ],
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
