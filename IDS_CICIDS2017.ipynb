{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parmigggiana/ml-ids/blob/main/IDS_CICIDS2017.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tGLYJuXmFBZI"
      },
      "source": [
        "# Web attack detection using CICIDS2017 dataset"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lnuSXVKD8HKk"
      },
      "source": [
        "This is an edited version of the original https://github.com/fisher85/ml-cybersecurity/blob/master/python-web-attack-detection/web-attack-detection.ipynb\n",
        "\n",
        "I have adapted the script to use the [corrected CIC-IDS-2017 dataset](https://intrusion-detection.distrinet-research.be/CNS2022/index.html).\n",
        "Instead of selecting a single day, I used the whole dataset (~2 mil. entries).\n",
        "The script was written and corrected iterating on only one of those days, to make it easier to test that everything was working as intended. After it was done, I re-ran it with all the available data overnight and saved the results.\n",
        "I changed the math in the undersampling section to make it easier and more direct. I also chose to only undersample based on probability instead of having an hard limit. Given the size of the dataset, this is mostly ininfluent.\n",
        "I have also re-done the feature selection and analysis.\n",
        "The original trained and selected features on the whole dataset, causing obvious overfitting. After the data preparation I took out a portion of the dataset which was never used again, if not for the final test after everything else was set.  \n",
        "After that, I added testing on the corrected CSE-CIC-IDS-2018 dataset and on my own CTF Dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SCEkDfpOFPQX"
      },
      "source": [
        "## Data preprocessing\n",
        "\n",
        "Source: https://github.com/bozbil/Anomaly-Detection-in-Networks-Using-Machine-Learning/blob/master/01_preprocessing.ipynb [Kostas2018]."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Download and clean data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gX6aYMEKqe1K"
      },
      "source": [
        "I will use the corrected CIC-IDS-2017 instead of the original."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9A526YEoqe1K"
      },
      "outputs": [],
      "source": [
        "#!wget https://intrusion-detection.distrinet-research.be/CNS2022/Datasets/CICIDS2017_improved.zip -O dataset.zip\n",
        "#!unzip -u -d Corrected_CICIDS2017/ dataset.zip "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "i4vnx_OaGAl0"
      },
      "source": [
        "Using encoding='latin' avoids the UnicodeDecodeError we get otherwise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIqeKHKYGCoz"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "li = []\n",
        "for filename in Path('./Corrected_CICIDS2017/').glob('*.csv'):\n",
        "  li.append(pd.read_csv(filename, index_col=0, encoding='latin'))\n",
        "df = pd.concat(li, axis=0, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 869
        },
        "id": "IXElh2cwhwa2",
        "outputId": "3e4ec157-4733-4f28-ab09-a8f53fdab2f7"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMkibc_W4hpQ",
        "outputId": "6d1318ce-3cba-4423-f379-68472881f90d"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HX-OJjpP_74V"
      },
      "source": [
        "As for the differences between the features, aside for a couple of names that changed slightly, the corrected datasets adds 5 features: 'Fwd RST Flags', 'Bwd RST Flags', 'ICMP Code', 'ICMP Type', 'Total TCP Flow Time'. It also removed the duplicated feature 'Fwd Header Length.1'.\n",
        "Other than that, there's a column 'Attempted'. This should not be treated as a feature by the machine learning model. As suggested by the paper authors, we treat all those samples ad benign."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84u_ejOLDs23"
      },
      "outputs": [],
      "source": [
        "def clean_attempted(row):\n",
        "  if row['Attempted Category'] != -1:\n",
        "    row['Label'] = 'BENIGN'\n",
        "  return row\n",
        "\n",
        "df = df.apply(clean_attempted, axis=1)\n",
        "df = df.drop(columns='Attempted Category')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BIQQvtxZhiTZ"
      },
      "source": [
        "When assessing the distribution of labels, it turns out that out of 2099976 records there are many benign records - 1594545 to be exact."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrGLjk5nhrGE",
        "outputId": "5f46bcbf-018d-48cd-a3ad-6322d30f3f29"
      },
      "outputs": [],
      "source": [
        "df['Label'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnpQqQ8fhxwN",
        "outputId": "9a6df781-a74a-43db-f01f-742449e2960d"
      },
      "outputs": [],
      "source": [
        "df['Label'].value_counts()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "l7lpytF7h6D4"
      },
      "source": [
        "Delete blank records. This shouldn't make a difference since the new dataset already has no blank records."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ltfHW8dh7Tw",
        "outputId": "d75eac09-826b-48f0-91aa-870a52052e1e"
      },
      "outputs": [],
      "source": [
        "df = df.drop(df[pd.isnull(df['Flow ID'])].index)\n",
        "df.shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZN6DKttXiH7J"
      },
      "source": [
        "The \"Flow Bytes/s\" and \"Flow Packets/s\" columns have non-numerical values, replace them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZ2ffToLi02x"
      },
      "outputs": [],
      "source": [
        "df.replace('Infinity', -1, inplace=True)\n",
        "df[[\"Flow Bytes/s\", \"Flow Packets/s\"]] = df[[\"Flow Bytes/s\", \"Flow Packets/s\"]].apply(pd.to_numeric)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OAVqCLK8qe1P"
      },
      "source": [
        "Replace the NaN values and infinity values with -1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgZGWpa0qe1P"
      },
      "outputs": [],
      "source": [
        "df.replace([np.inf, -np.inf, np.nan], -1, inplace=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2JMv7gKfi4nI"
      },
      "source": [
        "Convert string characters to numbers, use LabelEncoder, not OneHotEncoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmYOMG0Ti8Wh",
        "outputId": "b6ed6681-99c3-4d69-83fa-2e7933e9d007"
      },
      "outputs": [],
      "source": [
        "string_features = list(df.select_dtypes(include=['object']).columns)\n",
        "string_features.remove('Label')\n",
        "string_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySZ2eW_2jCfQ"
      },
      "outputs": [],
      "source": [
        "le = preprocessing.LabelEncoder()\n",
        "df[string_features] = df[string_features].apply(lambda col: le.fit_transform(col))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.to_csv(\"web_attacks_unbalanced.csv\", index=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "K94al8HAjJEN"
      },
      "source": [
        "### Undersampling against unbalance\n",
        "\n",
        "Dataset is unbalanced: total records = 2099976, \"BENIGN\" records = 1594545, records with attacks much less: 11 + 13 + 18 + 36 + 73 + 736 + 1740 + 2961 + 3859 + 3972 + 7567 + 71767 + 95144 + 158468 + 159066 = 505431."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('web_attacks_unbalanced.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7K7iWbNMjWrZ",
        "outputId": "c6792868-a8d0-49a9-a7b2-06bb5994be36"
      },
      "outputs": [],
      "source": [
        "benign_total = len(df[df['Label'] == \"BENIGN\"])\n",
        "benign_total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVs_xEHFjY5q",
        "outputId": "c25f60fc-8185-488a-8b10-a5a123bc4510"
      },
      "outputs": [],
      "source": [
        "attack_total = len(df[df['Label'] != \"BENIGN\"])\n",
        "attack_total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFvPOea2jhMt",
        "outputId": "81348180-5080-4ea3-8aed-395fa1445c78"
      },
      "outputs": [],
      "source": [
        "df['Label'].value_counts()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6A9-rS7OjyFl"
      },
      "source": [
        "We use **undersampling** to correct class imbalances: we remove most of the \"BENIGN\" records.\n",
        "\n",
        "Form a balanced dataset web_attacks_balanced.csv in proportion: 70% benign data, 30% attacks (2099976 total: x attacks, 1179339 benign).\n",
        "\n",
        "Algorithm to form a balanced df_balanced dataset:\n",
        "\n",
        "* All the records with the attacks are copied to the new dataset.\n",
        "* There are two conditions for copying \"BENIGN\" records to the new dataset:\n",
        "\n",
        "     1. The next record is copyied with the benign_inc_probability.\n",
        "     2. The total number of \"BENIGN\" records must not exceed the limit of 5087 records."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aVZutNOZj_N9"
      },
      "source": [
        "Ð¡alculate the probability of copying a \"BENIGN\" record."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaW7sEjHkB3K",
        "outputId": "6b97aa54-d221-4262-9613-b1d45edb9e88"
      },
      "outputs": [],
      "source": [
        "total_samples = len(df[df['Label'] != 'BENIGN']) // 0.3\n",
        "benign_included_max = round(total_samples * 0.7)\n",
        "benign_inc_probability = benign_included_max / benign_total\n",
        "print(benign_included_max, benign_inc_probability)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "G3ZXh6fTkFK_"
      },
      "source": [
        "Copy records from df to df_balanced, save dataset **web_attacks_balanced.csv**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MdiMPmdkICk"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "indexes = []\n",
        "benign_included_count = 0\n",
        "for index, row in df.iterrows():\n",
        "    if (row['Label'] == \"BENIGN\"):\n",
        "      # Have we achieved 70%?\n",
        "      #if benign_included_count > benign_included_max: continue\n",
        "      # Copying with benign_inc_probability\n",
        "      if random.random() > benign_inc_probability: continue\n",
        "      benign_included_count += 1\n",
        "\n",
        "    indexes.append(index)\n",
        "\n",
        "df_balanced = df.loc[indexes]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqypBDIdkKN4",
        "outputId": "afb8fb0b-f26f-418e-b061-e1317cae4dcb"
      },
      "outputs": [],
      "source": [
        "df_balanced['Label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(df_balanced[df_balanced['Label'] == 'BENIGN'])/len(df_balanced)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qiYFzlGkkSXe"
      },
      "outputs": [],
      "source": [
        "df_balanced.to_csv(\"web_attacks_balanced.csv\", index=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-IEyQxBDt5sG"
      },
      "source": [
        "### Preparing data for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbLOn76hqe1S"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('web_attacks_balanced.csv')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_G2VS_p_qe1Y"
      },
      "source": [
        "The Label column is encoded as follows: \"BENIGN\" = 0, attack = 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRoX90Thqe1Y"
      },
      "outputs": [],
      "source": [
        "df['Label'] = df['Label'].apply(lambda x: 0 if x == 'BENIGN' else 1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1k2G5UAEt9cw"
      },
      "source": [
        "7 features (Flow ID, Source IP, Source Port, Destination IP, Destination Port, Protocol, Timestamp) are excluded from the dataset. The hypothesis is that the \"shape\" of the data being transmitted is more important than these attributes. In addition, ports and addresses can be substituted by an attacker, so it is better that the ML algorithm does not take these features into account in training [Kostas2018]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "8yza95R2t_1N",
        "outputId": "4cf1c1b2-65aa-4503-9411-f8c947f740fa"
      },
      "outputs": [],
      "source": [
        "excluded = ['Flow ID', 'Src IP', 'Src Port', 'Dst IP', 'Dst Port', 'Protocol', 'Timestamp']\n",
        "df = df.drop(columns=excluded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-FDOBmOufo6",
        "outputId": "ac46d0ac-2478-4d2c-af4b-a795b5ae0146"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"definitive_dataset.csv\", index=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3P69z9kfupES"
      },
      "source": [
        "## Feature importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df.sample(500000) # randomly take 500k samples for hyperparameters selection\n",
        "y = df['Label'].values\n",
        "X = df.drop(columns=['Label'])\n",
        "print(X.shape, y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BbvfnjTuzeX",
        "outputId": "d423facc-8398-411a-add9-387678a88027"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=241)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "duGKUsAzal52"
      },
      "source": [
        "### Evaluation of importance using RandomForestClassifier.feature_importances_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xo4E_wFeaqNd",
        "outputId": "8816170d-c713-4845-a2d2-a2b4a3a6e4b9"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=150, random_state=42, oob_score=True)\n",
        "rf.fit(X_train, y_train)\n",
        "# Score = mean accuracy on the given test data and labels\n",
        "print('R^2 Training Score: {:.2f} \\nR^2 Validation Score: {:.2f} \\nOut-of-bag Score: {:.2f}'\n",
        "      .format(rf.score(X_train, y_train), rf.score(X_test, y_test), rf.oob_score_))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "htO0aM5AXCoN"
      },
      "source": [
        "We select all the features with importance at least 1%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byV6krktawE_",
        "outputId": "e439cb68-e7b3-46d3-cfbd-e6c85d047cd5"
      },
      "outputs": [],
      "source": [
        "features = X.columns\n",
        "importances = rf.feature_importances_\n",
        "indices = np.argsort(importances)[::-1]\n",
        "webattack_features = []\n",
        "\n",
        "for index, i in enumerate(indices):\n",
        "    if importances[i] >= 0.01:\n",
        "      webattack_features.append(features[i])\n",
        "    print(f'{index+1}. \\t #{i} \\t {importances[i]:.3f} \\t {features[i]}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "eF02L27nV5Ye"
      },
      "source": [
        "Visualize what we're left with"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "TPxzWeP4bHa5",
        "outputId": "1d601152-15fa-4796-c99e-90fd568283db"
      },
      "outputs": [],
      "source": [
        "indices = np.argsort(importances)[-len(webattack_features):]\n",
        "plt.rcParams['figure.figsize'] = (11, 6)\n",
        "plt.title('Feature Importances')\n",
        "plt.barh(range(len(indices)), importances[indices], color='#cccccc', align='center')\n",
        "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
        "plt.xlabel('Relative Importance')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaYCrMC4cenU",
        "outputId": "0836bdeb-829b-40da-9390-5ba1b11d4977"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_pred = rf.predict(X_test)\n",
        "confusion_matrix(y_test, y_pred)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "eLikdx9Legm0"
      },
      "source": [
        "## Analysis of selected features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 852
        },
        "id": "l4AlTAUme5aJ",
        "outputId": "94c900e3-2c72-4588-a2ac-607be0075992"
      },
      "outputs": [],
      "source": [
        "\n",
        "frame_attacks = df[df['Label'] == 1]\n",
        "frame_benigns = df[df['Label'] == 0]\n",
        "plt.figure(figsize=(30,45))\n",
        "for i, feat in enumerate(webattack_features):\n",
        "    plt.subplot(len(webattack_features)//3+1, 3, i+1)\n",
        "    x1 = sorted(frame_benigns[feat])\n",
        "    x2 = sorted(frame_attacks[feat])\n",
        "    fr = [x1, x2]\n",
        "    plt.hist([x for x in fr if x != (0, 0)], bins=150, density=True, stacked=True)\n",
        "    plt.title(feat)\n",
        "    plt.legend(['benign', 'attacks'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "IIqD-DjrgbIr",
        "outputId": "f3cb3e17-05be-4d12-ae1a-caf7d7238af5"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "corr_matrix = df[webattack_features].corr()\n",
        "plt.rcParams['figure.figsize'] = (18, 8)\n",
        "g = sns.heatmap(corr_matrix, annot=True, fmt='.1g', cmap='Greys')\n",
        "g.set_xticklabels(g.get_xticklabels(), verticalalignment='top', horizontalalignment='right', rotation=30);\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "r2J6Pz0xglza"
      },
      "source": [
        "Remove correlated features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nml7xnnqgoMz"
      },
      "outputs": [],
      "source": [
        "to_be_removed = {'Packet Length Std', 'Bwd Packet Length Std', 'Bwd Segment Size Avg', 'Bwd Packet Length Max', 'Bwd Packet Length Mean', 'Packet Length Max', 'Packet length Max', 'Packet Length Mean', 'Average Packet Size', 'Subflow Bwd Bytes', 'Fwd RST Flags', 'Subflow Fwd Bytes', 'Fwd Segment Size Avg'}\n",
        "webattack_features = [item for item in webattack_features if item not in to_be_removed]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "id": "vHbm-bkbgDw8",
        "outputId": "499b6ed4-8255-4e65-ed91-a23eb2d839eb"
      },
      "outputs": [],
      "source": [
        "corr_matrix = df[webattack_features].corr()\n",
        "plt.rcParams['figure.figsize'] = (12, 5)\n",
        "sns.heatmap(corr_matrix, annot=True, fmt='.1g', cmap='Greys');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(webattack_features)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "eh-k8KdMhJ_Q"
      },
      "source": [
        "## Hyperparameter selection"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hZtnTrlNk_Uf"
      },
      "source": [
        "### Grid search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaeAf6VRhwJq"
      },
      "outputs": [],
      "source": [
        "parameters = {'n_estimators': [20, 30, 50, 70],\n",
        "              'min_samples_leaf': [4, 3, 2],\n",
        "              'max_features': ['sqrt', 'log2', 5, 12, None],\n",
        "              'max_depth': [3, 5, 8, None]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152
        },
        "id": "O3ziP5BolEss",
        "outputId": "fb519c70-52f8-4191-8797-87b0079367b3"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "X_train = X_train[webattack_features]\n",
        "X_test = X_test[webattack_features]\n",
        "\n",
        "rfc = RandomForestClassifier(criterion='gini', random_state=6, oob_score=True, n_jobs=-1)\n",
        "gcv = GridSearchCV(rfc, parameters, scoring='f1', refit='f1', cv=3, return_train_score=True, verbose=10, n_jobs=2)\n",
        "gcv.fit(X_train, y_train)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vwi5Ds61mirz"
      },
      "source": [
        "Let's take a look at the results of the parameter selection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxeUXPHHmk3C",
        "outputId": "c42f5586-7592-4c61-922a-a2a9ec617199"
      },
      "outputs": [],
      "source": [
        "gcv.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VFX3ERUmlvk",
        "outputId": "35426ddd-bef4-4b04-bdbc-fcda8f90facd"
      },
      "outputs": [],
      "source": [
        "gcv.best_score_"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Iiskwr3VmoL5"
      },
      "source": [
        "## Final model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVJU_2TPqe1m",
        "outputId": "f1aa59b4-2a17-4766-84be-c007e6a385fd"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('definitive_dataset.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y = df['Label']\n",
        "X = df[webattack_features] \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "7F8aWhX3mm8B",
        "outputId": "064c9255-d1d6-4221-ed4f-b0680142c7a6"
      },
      "outputs": [],
      "source": [
        "#rfc = RandomForestClassifier(criterion='gini', max_depth=20, max_features=3, min_samples_leaf=2, n_estimators=25, random_state=42, oob_score=True)\n",
        "rfc = gcv.best_estimator_\n",
        "rfc.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yULIEGsxmtsQ",
        "outputId": "8de74beb-556a-4630-b207-413df18f09f8"
      },
      "outputs": [],
      "source": [
        "features = rfc.feature_names_in_\n",
        "importances = rfc.feature_importances_\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "for index, i in enumerate(indices):\n",
        "    print(f'{index+1}. \\t #{i} \\t {importances[i]:.3f} \\t {features[i]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWgbCOjZoIYX",
        "outputId": "ecd7d03f-a8f2-4fdb-adca-7d369d5942e9"
      },
      "outputs": [],
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "y_pred = rfc.predict(X_test)\n",
        "\n",
        "Accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "Precision = metrics.precision_score(y_test, y_pred)\n",
        "Recall = metrics.recall_score(y_test, y_pred)\n",
        "F1 = metrics.f1_score(y_test, y_pred)\n",
        "fpr, tpr, threasholds = metrics.roc_curve(y_test, y_pred)\n",
        "auroc = metrics.roc_auc_score(y_test, y_pred)\n",
        "\"\"\" \n",
        "Confusion matrix:\n",
        "\n",
        "      0  1 - predicted value (Wikipedia uses different convention for axes)\n",
        "    0 TN FP\n",
        "    1 FN TP \n",
        "\"\"\"\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(f'{Accuracy = }')\n",
        "print(f'{Precision = }')\n",
        "print(f'{Recall = }')\n",
        "print(f\"Area Under ROC Curve = {auroc}\")\n",
        "print(f'{F1 = }')\n",
        "plt.figure(figsize=(5,4))\n",
        "plt.plot(fpr, tpr)\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5PElFLh5oYzU"
      },
      "source": [
        "## Model saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QjZyFNFIoMFK"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('rf_model.pkl', 'wb') as f:\n",
        "    pickle.dump(rfc, f)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pnHSPBrDodIs"
      },
      "source": [
        "## Intra-Dataset testing\n",
        "\n",
        "We tested against CIC-IDS-2017 mostly as control - now we should evaluate performance against a similar dataset, the corrected CSE-CIC-IDS-2018"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "98uX2hrvofRR"
      },
      "source": [
        "Open the previously saved model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "from pathlib import Path\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "hxBtpLABob_z",
        "outputId": "8553e78f-fad6-40df-a7fb-f36a9bf5b1b5"
      },
      "outputs": [],
      "source": [
        "with open('rf_model.pkl', 'rb') as f:\n",
        "    rfc: RandomForestClassifier = pickle.load(f)\n",
        "rfc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!wget https://intrusion-detection.distrinet-research.be/CNS2022/Datasets/CSECICIDS2018_improved.zip -O 2018dataset.zip\n",
        "#!unzip -u -d Corrected_CSECICIDS2018/ 2018dataset.zip "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Due to the size of the dataset it is impossible to load it all at once.\n",
        "So I define two functions that I can call easily on each file. \n",
        "Since we have the same characteristics, the data pipeline is the same as before minus the undersampling, and we directly selected the relevant features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_data(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    def clean_attempted(row):\n",
        "        if row['Attempted Category'] != -1:\n",
        "            row['Label'] = 'BENIGN'\n",
        "        return row\n",
        "\n",
        "    df = df.apply(clean_attempted, axis=1)\n",
        "    df.drop(columns='Attempted Category', inplace=True)\n",
        "    #print('Cleaned Attempted')\n",
        "\n",
        "    df.drop(df[pd.isnull(df['Flow ID'])].index, inplace=True)\n",
        "\n",
        "    df.replace('Infinity', -1, inplace=True)\n",
        "    df[[\"Flow Bytes/s\", \"Flow Packets/s\"]] = df[[\"Flow Bytes/s\", \"Flow Packets/s\"]].apply(pd.to_numeric)\n",
        "\n",
        "    df.replace([np.inf, -np.inf, np.nan], -1, inplace=True)\n",
        "\n",
        "    df['Label'] = df['Label'].apply(lambda x: 0 if x == 'BENIGN' else 1)\n",
        "\n",
        "    le = LabelEncoder()\n",
        "    string_features = list(df.select_dtypes(include=['object']).columns)\n",
        "    df[string_features] = df[string_features].apply(lambda col: le.fit_transform(col))\n",
        "\n",
        "    feats = list(features)\n",
        "    feats.append('Label')\n",
        "    return df[feats]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def eval_metrics(df: pd.DataFrame) -> None:\n",
        "\n",
        "    y_test = df['Label']\n",
        "    X_test = df.drop(columns='Label')\n",
        "    #print('Predicting')\n",
        "    y_pred = rfc.predict(X_test)\n",
        "\n",
        "    #print('Computing scores')\n",
        "    Accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "    Precision = metrics.precision_score(y_test, y_pred)\n",
        "    Recall = metrics.recall_score(y_test, y_pred)\n",
        "    F1 = metrics.f1_score(y_test, y_pred)\n",
        "    fpr, tpr, threasholds = metrics.roc_curve(y_test, y_pred)\n",
        "    auroc = metrics.roc_auc_score(y_test, y_pred)\n",
        "    \"\"\" \n",
        "    Confusion matrix:\n",
        "\n",
        "        0  1 - predicted value (Wikipedia uses different convention for axes)\n",
        "        0 TN FP\n",
        "        1 FN TP \n",
        "    \"\"\"\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "    print(f'{Accuracy = }')\n",
        "    print(f'{Precision = }')\n",
        "    print(f'{Recall = }')\n",
        "    print(f\"Area Under ROC Curve = {auroc}\")\n",
        "    print(f'{F1 = }')\n",
        "    plt.figure(figsize=(5,4))\n",
        "    plt.plot(fpr, tpr)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "outputs": [],
      "source": [
        "for filename in Path('./Corrected_CSECICIDS2018/').glob('*.csv'):\n",
        "  print(f\"{filename}\")\n",
        "  df = pd.read_csv(filename, index_col=0, encoding='latin').sample(1_000_000) # We only sample a milion because the whole file saturates the RAM and causes the computer to freeze\n",
        "  #print(df.shape)\n",
        "  df = prepare_data(df)\n",
        "  eval_metrics(df)\n",
        "\n",
        "# input(\"Press enter to continue\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## OOD Testing\n",
        "\n",
        "Evaluating performance on a different dataset is harder, especially if they don't have a similar set of features"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "SCEkDfpOFPQX",
        "-IEyQxBDt5sG",
        "wE4AwrX1u6Hj",
        "suPDWnoYaEPD",
        "duGKUsAzal52",
        "eLikdx9Legm0"
      ],
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
